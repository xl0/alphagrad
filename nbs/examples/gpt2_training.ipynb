{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-Nano training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tidygrad as tg\n",
    "from tidygrad import Tensor\n",
    "import tidygrad.tensor\n",
    "import numpy as np\n",
    "\n",
    "import huggingface_hub\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ds = datasets.load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_vocab = 1024\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "ndim = 512\n",
    "ctx_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def gpt2_new(n_vocab, n_layers, n_heads, ndim):\n",
    "    shape_dict = {\n",
    "        \"wte\": [n_vocab, ndim],\n",
    "        \"wpe\": [ctx_len, ndim],\n",
    "        \"ln_f.weight\": [ndim],\n",
    "        \"ln_f.bias\": [ndim],\n",
    "    }\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        shape_dict[f\"h.{i}.ln_1.weight\"] = [ndim]\n",
    "        shape_dict[f\"h.{i}.ln_1.bias\"] = [ndim]\n",
    "\n",
    "        shape_dict[f\"h.{i}.attn.c_attn.weight\"] = [ndim, 3 * ndim]\n",
    "        shape_dict[f\"h.{i}.attn.c_attn.bias\"] = [3 * ndim]\n",
    "\n",
    "        shape_dict[f\"h.{i}.attn.c_proj.weight\"] = [ndim, ndim]\n",
    "        shape_dict[f\"h.{i}.attn.c_proj.bias\"] = [ndim]\n",
    "\n",
    "        shape_dict[f\"h.{i}.ln_2.weight\"] = [ndim]\n",
    "        shape_dict[f\"h.{i}.ln_2.bias\"] = [ndim]\n",
    "\n",
    "        shape_dict[f\"h.{i}.mlp.c_fc.weight\"] = [ndim, 4 * ndim]\n",
    "        shape_dict[f\"h.{i}.mlp.c_fc.bias\"] = [4 * ndim]\n",
    "\n",
    "        shape_dict[f\"h.{i}.mlp.c_proj.weight\"] = [4 * ndim, ndim]\n",
    "        shape_dict[f\"h.{i}.mlp.c_proj.bias\"] = [ndim]\n",
    "\n",
    "    return tg.model.Model(shape_dict)\n",
    "\n",
    "model = gpt2_new(n_vocab=n_vocab, n_layers=n_layers, n_heads=n_heads, ndim=ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = Tensor(123, requires_grad=False)\n",
    "t1 = t + t\n",
    "\n",
    "t1.requires_grad is False\n",
    "t1.parents is []\n",
    "\n",
    "t1.requires_grad(True)\n",
    "\n",
    "t1.requires_grad is True\n",
    "\n",
    "But it has no parents!!!1\n",
    "\n",
    "t1.op should be Load, not Add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def gpt2_init(model):\n",
    "    for k in model.params.keys():\n",
    "        if k.endswith(\".weight\"):\n",
    "            model.params[k] = Tensor(np.random.randn(*model.params[k].shape), name=k) * 0.02\n",
    "        elif k.endswith(\".bias\"):\n",
    "            model.params[k] = Tensor(np.zeros(model.params[k].shape), name=k)\n",
    "\n",
    "    model.params[\"wte\"] = Tensor(np.random.randn(*model.params[\"wte\"].shape), name=\"wte\") * 0.02\n",
    "    model.params[\"wpe\"] = Tensor(np.random.randn(*model.params[\"wpe\"].shape), name=\"wpe\") * 0.01\n",
    "\n",
    "gpt2_init(model)\n",
    "model.requires_grad(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidygrad.tensor._num_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tidygrad.func as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def gpt2_transformer_block(model: tg.model.Model, x, n_heads, i):\n",
    "    def get_params(s):\n",
    "        return model.params[f\"h.{i}.{s}\"]\n",
    "\n",
    "    ln_1 = F.layer_norm(x, get_params(\"ln_1.weight\"), get_params(\"ln_1.bias\"))\n",
    "\n",
    "    attn_w_qkv = get_params(\"attn.c_attn.weight\")\n",
    "    attn_b_qkv = get_params(\"attn.c_attn.bias\")\n",
    "\n",
    "    attn_w_q, attn_w_k, attn_w_v = attn_w_qkv.split(3, axis=-1)\n",
    "    attn_b_q, attn_b_k, attn_b_v = attn_b_qkv.split(3, axis=-1)\n",
    "\n",
    "    q = ln_1.mmul(attn_w_q) + attn_b_q\n",
    "    k = ln_1.mmul(attn_w_k) + attn_b_k\n",
    "    v = ln_1.mmul(attn_w_v) + attn_b_v\n",
    "\n",
    "    q_chunked = F.stack(q.split(n=n_heads, axis=-1), axis=0)\n",
    "    k_chunked = F.stack(k.split(n=n_heads, axis=-1), axis=0)\n",
    "    v_chunked = F.stack(v.split(n=n_heads, axis=-1), axis=0)\n",
    "\n",
    "    dim = q_chunked.shape[-1]\n",
    "    attention = q_chunked.mmul(k_chunked.transpose(-1, -2)) / np.sqrt(dim / n_heads)\n",
    "\n",
    "    mask = np.tril(np.ones(attention.shape), k=0)\n",
    "    ee = np.exp(attention) * mask\n",
    "\n",
    "    softmaxed = ee / ee.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    attention_output = softmaxed.mmul(v_chunked)\n",
    "    attention_chunks = attention_output.split(axis=0, n=n_heads)\n",
    "    # print(\"attention_chunks\", attention_chunks)\n",
    "\n",
    "    attention_reshaped = F.concat(attention_chunks, axis=-1)\n",
    "    attention_reshaped = attention_reshaped[0]\n",
    "    # print(\"attention_reshaped\", attention_reshaped)\n",
    "\n",
    "    cproj_w = get_params(\"attn.c_proj.weight\")\n",
    "    cproj_b = get_params(\"attn.c_proj.bias\")\n",
    "    # attention_reshaped = Tensor(attention_reshaped_np)\n",
    "\n",
    "    crosstalk = attention_reshaped.mmul(cproj_w) + cproj_b\n",
    "\n",
    "    after_residual = crosstalk + x\n",
    "    # print(\"after_residual\", after_residual)\n",
    "    ln2_w = get_params(\"ln_2.weight\")\n",
    "    ln2_b = get_params(\"ln_2.bias\")\n",
    "\n",
    "    after_ln2 = F.layer_norm(after_residual, ln2_w, ln2_b)\n",
    "\n",
    "    mlp_c_fc_w = get_params(\"mlp.c_fc.weight\")\n",
    "    mlp_c_fc_b = get_params(\"mlp.c_fc.bias\")\n",
    "\n",
    "    after_up = after_ln2.mmul(mlp_c_fc_w) + mlp_c_fc_b\n",
    "    # print(\"after_up\", after_up)\n",
    "\n",
    "    after_up_a = F.gelu(after_up)\n",
    "    # print(\"after_up_a\", after_up_a)\n",
    "\n",
    "    mlp_c_proj_w = get_params(\"mlp.c_proj.weight\")\n",
    "    mlp_c_proj_b = get_params(\"mlp.c_proj.bias\")\n",
    "\n",
    "    after_down = after_up_a.mmul(mlp_c_proj_w) + mlp_c_proj_b\n",
    "\n",
    "    output = after_down + after_residual\n",
    "    return output\n",
    "\n",
    "def gpt2(model, input, n_layers, n_heads):\n",
    "    def get_params(s):\n",
    "        return model.params[s]\n",
    "\n",
    "    token_embeddings = F.embedding(get_params(\"wte\"), input)\n",
    "    position_embeddings = F.embedding(get_params(\"wpe\"), np.arange(input.shape[-1]))\n",
    "\n",
    "    x = token_embeddings + position_embeddings\n",
    "\n",
    "    # print(\"first embedding\", x)\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        print(\"layer\", i)\n",
    "        x = gpt2_transformer_block(model=model, x=x, n_heads=n_heads, i=i)\n",
    "\n",
    "    return F.layer_norm(x, w=get_params(\"ln_f.weight\"), b=get_params(\"ln_f.bias\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# res = gpt2(model, np.arange(256).reshape(2, -1), n_layers=n_layers, n_heads=n_heads)\n",
    "# res.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# from tidygrad.training import one_hot_encode_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(batch, n_classes):\n",
    "    batch_size, sequence_length = batch.shape\n",
    "    one_hot = np.zeros((batch_size, sequence_length, n_classes))\n",
    "    rows, cols = np.indices((batch_size, sequence_length))\n",
    "    one_hot[rows, cols, batch] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def language_modeling_loss(model, input, target, n_layers, n_heads):\n",
    "    res = gpt2(model, input, n_layers, n_heads)\n",
    "    # print(\"res\", res)\n",
    "    # print(\"wte\", model.params[\"wte\"])\n",
    "    logits = res.mmul(model.params[\"wte\"].transpose(-1, -2), name=\"logits\")\n",
    "\n",
    "    # print(\"logits\", logits)\n",
    "    loss = F.CrossEntropy_loss(logits, one_hot_encode(target, n_classes=n_vocab))\n",
    "    return loss\n",
    "\n",
    "# loss = language_modeling_loss(\n",
    "#     model, input=np.random.randint(0, n_vocab, size=(2, ctx_len)), target=np.random.randint(0, n_vocab, size=(2, ctx_len)), n_layers=n_layers, n_heads=n_heads\n",
    "# )\n",
    "\n",
    "# print(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# np.seterr(all=\"raise\")\n",
    "# l = loss.sum()\n",
    "# print(loss)\n",
    "\n",
    "# l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"datasets/TinyStories/TinyStories.txt\", \"r\") as file:\n",
    "#     tokens = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset:\n",
    "\n",
    "# dataset = [\"Lilly gsdsgfsdfsd sf sfds\"] <- You can no sample from ths\n",
    "\n",
    "# dataset = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15.....]\n",
    "\n",
    "# ctx len = 5\n",
    "\n",
    "# dataset[0] = [1,2,3,4,5]\n",
    "# dataset[1] = [2,3,4,5,6]\n",
    "# dataset[2] = [3,4,5,6,7]\n",
    "# dataset[3] = [4,5,6,7,8]\n",
    "\n",
    "from tidygrad.utils.datasets import Dataset, DataLoader\n",
    "\n",
    "tokens = np.load(\"./datasets/TinyStories/TinyStories_1percent_ids.npy\")\n",
    "\n",
    "class TSDataset(Dataset):\n",
    "    def __init__(self, token_array, ctx_len):\n",
    "        self.token_array = token_array\n",
    "        self.ctx_len = ctx_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_array) - self.ctx_len - 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.token_array[i:i + self.ctx_len], self.token_array[i + 1:i + self.ctx_len + 1]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        # print(\"batch\", batch) # [(x1, y1), (x2, y2), (x3, y3)]\n",
    "        return np.stack([x for x, y in batch]), np.stack([y for x, y in batch])\n",
    "\n",
    "dataset = TSDataset(tokens, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TSDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, batch_tfms=None, ctx_len=128, fake_epoch_len=50, seed=1337):\n",
    "        super().__init__(dataset=dataset, batch_size=batch_size, batch_tfms=batch_tfms)\n",
    "        self.fake_epoch_len = fake_epoch_len\n",
    "        self.ctx_len = ctx_len\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min((len(self.dataset) // self.batch_size) // self.ctx_len, self.fake_epoch_len)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= min(len(self), self.fake_epoch_len):\n",
    "            raise StopIteration\n",
    "\n",
    "        idxs = self.rng.integers(0, len(self.dataset), size=(self.batch_size, ))\n",
    "\n",
    "        batch = [self.dataset[i] for i in idxs]\n",
    "        batch = self.dataset.collate_fn(batch)\n",
    "\n",
    "        self.i += 1\n",
    "\n",
    "        return batch\n",
    "\n",
    "dataloader = TSDataLoader(dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tidygrad.utils.data import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (64, 2)\n",
      "y (64, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(dataloader))\n",
    "\n",
    "print(\"X\", X.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tidygrad.training import Learner\n",
    "\n",
    "from tidygrad.optim import Adam\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tidygrad.tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(X, y):\n",
    "    # y = Tensor(y)\n",
    "    logits = X.mmul(model.params[\"wte\"].transpose(-1, -2), name=\"logits\")\n",
    "\n",
    "    # print(\"X\", X)\n",
    "    # print(\"y\", y)\n",
    "    # print(\"logits\", logits)\n",
    "\n",
    "    one_one_hot = one_hot_encode(y, n_vocab)\n",
    "\n",
    "    loss = F.CrossEntropy_loss(logits, one_one_hot, reduction=\"sum\")\n",
    "\n",
    "    print(\"loss\", loss)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    print(\"post_epoch num tensors\", tidygrad.tensor._num_tensors)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tidygrad.training import DictLoggerCallback, ProgressBarCallback, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class OneBatchCallback:\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "\n",
    "    def post_loss(self, learner):\n",
    "        print(\"post_batch_backward\", self.i)\n",
    "        if self.i == 1:\n",
    "            raise Exception(\"post_batch_backward\")\n",
    "        self.i += 1\n",
    "\n",
    "class MemleakCallback:\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        print(\"init\")\n",
    "\n",
    "    def post_epoch(self, learner):\n",
    "        print(\"post_epoch num tensors\", tidygrad.tensor._num_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "model_funct = partial(gpt2, n_layers=n_layers, n_heads=n_heads)\n",
    "\n",
    "def model_funct(input):\n",
    "    return gpt2(model, input, n_layers=n_layers, n_heads=n_heads)\n",
    "\n",
    "optim = Adam(lr=0.001, params=model.parameter_list())\n",
    "\n",
    "ler = Learner(\n",
    "    model=model_funct,\n",
    "    dataloaders=DataLoaders(train=dataloader, test=dataloader),\n",
    "    loss_func=loss_function,\n",
    "    optimizer=optim,\n",
    "    callbacks=[DictLoggerCallback(metrics=[Loss()]),\n",
    "               ProgressBarCallback(metrics=[\n",
    "                   \"loss\", \n",
    "               ], plot_train_skip_ylim=15, plot_smooth_training=5),\n",
    "               MemleakCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7224b0db599b4af3ab9528274fcf853a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f314f1ed5d6e49959942efc7c018fad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b><pre>Ep  | loss       | val_loss  \n",
       "</pre></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.907, 6.951] μ=6.931 σ=0.009\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xl0/work/projects/grads/tidygrad/tidygrad/ops/common.py:190: RuntimeWarning: underflow encountered in multiply\n",
      "  self.parents[1].accum_grad(self.out.grad * self.parents[0].data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.857, 6.955] μ=6.923 σ=0.016\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.834, 6.955] μ=6.911 σ=0.029\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.784, 6.962] μ=6.901 σ=0.036\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.764, 6.973] μ=6.893 σ=0.047\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.735, 6.971] μ=6.885 σ=0.060\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.704, 6.964] μ=6.869 σ=0.069\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.670, 6.989] μ=6.873 σ=0.079\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.633, 6.989] μ=6.845 σ=0.092\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.598, 6.984] μ=6.832 σ=0.091\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.557, 7.014] μ=6.817 σ=0.119\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.515, 7.034] μ=6.804 σ=0.120\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.474, 7.022] μ=6.801 σ=0.148\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.432, 7.044] μ=6.734 σ=0.159\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.379, 7.049] μ=6.733 σ=0.181\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.327, 7.072] μ=6.711 σ=0.190\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.265, 7.108] μ=6.701 σ=0.214\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.203, 7.115] μ=6.640 σ=0.237\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.140, 7.161] μ=6.672 σ=0.268\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[6.072, 7.183] μ=6.612 σ=0.295\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.994, 7.174] μ=6.578 σ=0.325\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.919, 7.219] μ=6.550 σ=0.345\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.842, 7.261] μ=6.522 σ=0.385\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.759, 7.284] μ=6.491 σ=0.430\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.675, 7.331] μ=6.442 σ=0.425\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.581, 7.367] μ=6.363 σ=0.465\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.485, 7.441] μ=6.362 σ=0.529\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.392, 7.457] μ=6.390 σ=0.548\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.290, 7.479] μ=6.281 σ=0.602\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.184, 7.561] μ=6.285 σ=0.605\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[5.081, 7.624] μ=6.216 σ=0.691\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.975, 7.671] μ=6.272 σ=0.717\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.863, 7.779] μ=6.218 σ=0.756\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.745, 7.847] μ=6.051 σ=0.801\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.626, 7.890] μ=6.156 σ=0.895\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.506, 7.922] μ=5.963 σ=0.867\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.393, 8.021] μ=6.011 σ=0.977\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.286, 8.091] μ=5.989 σ=0.981\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n",
      "layer 0\n",
      "layer 1\n",
      "loss Tensor[64, 2, 1](name=\"\" op=Sum parents=[]):\n",
      "    v=array[64, 2, 1] f32 n=128 x∈[4.162, 8.158] μ=6.038 σ=1.007\n",
      "    ∇=array[64, 2, 1] f32 n=128 \u001b[38;2;127;127;127mall_zeros\u001b[0m\n",
      "post_epoch num tensors 325\n"
     ]
    }
   ],
   "source": [
    "ler.fit(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "print(tidygrad.tensor._num_tensors)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(tidygrad.tensor._num_tensors)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
