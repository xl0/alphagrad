{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | default_exp ops.shape\n",
    "import nbdev\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations: Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import numpy as np\n",
    "from tidygrad.ops import BaseOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class Stack(BaseOp):\n",
    "    \"\"\"Stack tensors along a new axis\"\"\"\n",
    "\n",
    "    name_template = \"stack({})\"\n",
    "    \n",
    "    def __init__(self, tensors, axis=0, name=None):\n",
    "        assert isinstance(tensors, (list, tuple))\n",
    "        super().__init__(*tensors, name=name)\n",
    "        self.axis = axis\n",
    "        self.set_out(np.stack([t.data for t in self.args], axis=axis))\n",
    "    \n",
    "    def backward(self):\n",
    "        self.check_backward()\n",
    "        key = [ slice(None) ] * len(self.out.shape)\n",
    "        for i, a in enumerate(self.args):\n",
    "            key[self.axis] = i\n",
    "\n",
    "            a.accum_grad(self.out.grad[tuple(key)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Concat(BaseOp):\n",
    "    \"\"\"Concat tensors along an existing axis\"\"\"\n",
    "\n",
    "    name_template = \"concat({})\"\n",
    "    \n",
    "    def __init__(self, tensors, axis=0, name=None):\n",
    "        super().__init__(*tensors, name=name)\n",
    "        self.axis = axis\n",
    "        self.set_out(np.concatenate([t.data for t in self.args], axis=axis))\n",
    "    \n",
    "    def backward(self):\n",
    "        self.check_backward()\n",
    "        prev_len = 0\n",
    "        key = [slice(None)] * len(self.out.shape)\n",
    "        for a in self.args:\n",
    "            start = prev_len                 # sum of all previous lenght in axis dimension\n",
    "            prev_len = start + a.shape[self.axis]\n",
    "            key[self.axis] = slice(start, prev_len)\n",
    "            a.accum_grad(self.out.grad[tuple(key)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
